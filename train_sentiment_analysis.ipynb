{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import pickle\n",
    "from random import shuffle\n",
    "from string import punctuation\n",
    "\n",
    "from nltk import download\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/kenfang/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/kenfang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kenfang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/kenfang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download('movie_reviews')\n",
    "download('punkt')\n",
    "download('stopwords')\n",
    "download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stopwords_eng = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(movie_review_words):\n",
    "    return [w for w in movie_review_words if w not in stopwords_eng and w not in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def bag_of_words(feature_words):\n",
    "    bag = {}\n",
    "    for w in feature_words:\n",
    "        bag[w] = bag.get(w, 0) + 1\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reviews_pos = []\n",
    "reviews_neg = []\n",
    "for fileid in movie_reviews.fileids('pos'):\n",
    "    words = extract_features(movie_reviews.words(fileid))\n",
    "    reviews_pos.append((bag_of_words(words), 'pos'))\n",
    "\n",
    "for fileid in movie_reviews.fileids('neg'):\n",
    "    words = extract_features(movie_reviews.words(fileid))\n",
    "    reviews_neg.append((bag_of_words(words), 'neg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "split_pct = .80\n",
    "\n",
    "def split_set(review_set):\n",
    "    split = int(len(review_set) * split_pct)\n",
    "    return review_set[:split], review_set[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "shuffle(reviews_pos)\n",
    "shuffle(reviews_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pos_train, pos_test = split_set(reviews_pos)\n",
    "neg_train, neg_test = split_set(reviews_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_set = pos_train + neg_train\n",
    "test_set = pos_test + neg_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = NaiveBayesClassifier.train(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "most_informative_feature = model.most_informative_features(500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "most_informative_words = []\n",
    "for i in range(len(most_informative_feature)):\n",
    "    most_informative_words.append(most_informative_feature[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_ngrams(s, n=1):\n",
    "    # Convert to lowercase\n",
    "    s = s.lower()\n",
    "\n",
    "    # Replace all non alphanumeric characters with space\n",
    "    s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "\n",
    "    # Break sentence in the token, remove empty tokens\n",
    "    tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "\n",
    "    ngrams_words = zip(*[tokens[i:] for i in range(n)])\n",
    "    return [\" \".join(ngram) for ngram in ngrams_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "informative_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def extract_informative_feature(reviews_words):\n",
    "    return [informative_lemmatizer.lemmatize(w) for w in reviews_words if w in most_informative_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ngram_review_pos = []\n",
    "ngram_review_neg = []\n",
    "for fileid in movie_reviews.fileids('pos'):\n",
    "    ngram_pos = generate_ngrams(movie_reviews.raw(fileid))\n",
    "    ngram_words_pos = extract_informative_feature(ngram_pos)\n",
    "    ngram_review_pos.append((bag_of_words(ngram_words_pos), 'pos'))\n",
    "for fileid in movie_reviews.fileids('neg'):\n",
    "    ngram_neg = generate_ngrams(movie_reviews.raw(fileid))\n",
    "    ngram_words_neg = extract_informative_feature(ngram_neg)\n",
    "    ngram_review_neg.append((bag_of_words(ngram_words_neg), 'neg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "shuffle(ngram_review_pos)\n",
    "shuffle(ngram_review_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ngram_pos_train, ngram_pos_test = split_set(ngram_review_pos)\n",
    "ngram_neg_train, ngram_neg_test = split_set(ngram_review_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ngram_train_set = ngram_pos_train + ngram_neg_train\n",
    "ngram_test_set = ngram_pos_test + ngram_neg_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ngram_review_model = NaiveBayesClassifier.train(ngram_train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.5\n"
     ]
    }
   ],
   "source": [
    "print(100 * accuracy(ngram_review_model, ngram_test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_file = open('sa_classifier.pickle', 'wb')\n",
    "pickle.dump(model, model_file)\n",
    "model_file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hosting-ml-as-microservice",
   "language": "python",
   "name": "hosting-ml-as-microservice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
